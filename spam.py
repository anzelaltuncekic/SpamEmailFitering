# -*- coding: utf-8 -*-
"""Spam

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1inNAtq7vfDXptOpXqsQdLUwY0bVhU2_L
"""

from google.colab import drive
drive.mount('/content/drive')

spam_text_path='/content/drive/My Drive/Spam Email Filtering-Anzel Öztürk/training/spam/'
legitimate_texts_path='/content/drive/My Drive/Spam Email Filtering-Anzel Öztürk/training/legitimate/' 

import os 
spam_list = []
legitimate_list = []
for root, dirs, files in os.walk(spam_text_path):
    for file in files:
        if file.endswith('.txt'):
            with open(os.path.join(root, file), 'r') as f:
                text = f.read()
                spam_list.append(text)
    print(spam_list) 
for root, dirs, files in os.walk(legitimate_texts_path):
    for file in files:
        if file.endswith('.txt'):
            with open(os.path.join(root, file), 'r') as f:
                text = f.read()
                legitimate_list.append(text)
    print(legitimate_list)

spam_words=[]
legitimate_words=[]
spam_new_words=[]
legitimate_new_words=[]


for i in legitimate_list:
  for word in i.lower().split():
      legitimate_words.append(word)

for i in spam_list:
  for word in i.lower().split():
     spam_words.append(word)      
  
for i in spam_words:
  if(i.isalnum() and i.isalpha()):
    spam_new_words.append(i)

for i in legitimate_words:
  if(i.isalnum() and i.isalpha()):
    legitimate_new_words.append(i)

import urllib
import operator

spam_top200=[]
legitimate_top200=[]
def spam_frequency(List):
  word_counter = {}
  for word in List:
      if len(word) > 0 and word != '\r\n':
          if word not in word_counter:
              word_counter[word] = 1
          else:
              word_counter[word] += 1 
              

  for i,word in enumerate(sorted(word_counter,key=word_counter.get,reverse=True)[:200]):
      print (i+1,word,word_counter[word])
      spam_top200.append(word)

  print("Top 200 of spam words : " ,spam_top200)    


def legitimate_frequency(List):
  word_counter = {}
  for word in List:
      if len(word) > 0 and word != '\r\n':
          if word not in word_counter:
              word_counter[word] = 1
          else:
              word_counter[word] += 1 
              

  for i,word in enumerate(sorted(word_counter,key=word_counter.get,reverse=True)[:200]):
      print (i+1,word,word_counter[word])
      legitimate_top200.append(word)

  print("Top 200 of legitimate words : " ,legitimate_top200)

spam_frequency(spam_new_words)

legitimate_frequency(legitimate_new_words)

frequency = {}
counter = 0
s_counter = 0
for a in spam_top200:
    for b in spam_top200:
        if a == b:
            counter += 1
            frequency[a] = [counter, s_counter]
            if a in legitimate_top200:
                s_counter += 1
                frequency[a] = [counter, s_counter]
               
    counter = 0
    s_counter = 0
for c in legitimate_top200:
    for d in legitimate_top200:
        if c == d:
            s_counter += 1
            if c in frequency:
                frequency[c][1] = s_counter
            elif c not in frequency:
                frequency[c] = [counter, s_counter]
    s_counter = 0

print(frequency)

def bayesian_estimation(Q, D,total_event):
    try:
        posterior_probability = (Q * D)/total_event
        return posterior_probability
    except ZeroDivisionError:
        return 0

def probability(test_texts):
  spam = 0
  for i in frequency:
      spam = spam + frequency[i][0]
  legitimate = 0
  for e in frequency:
      legitimate = legitimate + frequency[e][1]


  subjectline = test_texts
  data = subjectline.split()
  data_likelihood = {}


  for f in data:
      if f in frequency:
         word_frequency = frequency[f][0]
      else:
          word_frequency = 0
      data_likelihood[f] = word_frequency

  def theprobofclass(word):
      try:
          add_class = frequency[word][0] + frequency[word][1]
          return add_class
      except KeyError:
          return 0


  D = spam/(spam+legitimate)

  n = 0
  for g in data_likelihood:
      posterior_probability = bayesian_estimation(data_likelihood[g], D, theprobofclass(g))
      n += posterior_probability
  print("The Probablity of being spam : ", n)


  likelihood_word = {}
  for h in data:
      if h in frequency:
          word_frequency = frequency[h][1]
      else:
          word_frequency = 0
      likelihood_word[h] = word_frequency
    
  prior_probability = legitimate/(spam+legitimate)

  m = 0
  for i in likelihood_word:
      posterior_prob = bayesian_estimation(likelihood_word[i], prior_probability, theprobofclass(i))
      m += posterior_prob
  print("The Probability of being non spam : ", m)

  if n>m:
    print("This mail is a SPAM!!!")
    return 1
  elif n==m:
    print("This mail might be SPAM."),
    return 2
  else:
    print("This is not a SPAM")
    return 3

test_list = []
countofspams=0.0
countofequals=0.0
countofnonspams=0.0
x=[]
finalpath='/content/drive/My Drive/Spam Email Filtering-Anzel Öztürk/test/spam' 
for root, dirs, files in os.walk(finalpath):
    for file in files:
        if file.endswith('.txt'):
            
            with open(os.path.join(root, file), 'r') as f:
                text = f.read()
                string=' '
                print(string)
                test_list.append(text)
                spam_words1=[]
                spam_new_words1=[]                
                for i in test_list:
                  for word in i.lower().split():
                    spam_words1.append(word)  

                
                for i in spam_words1:
                  if (i.isalnum() and i.isalpha()):
                    spam_new_words1.append(i)
                
          
                string=string.join(spam_new_words1) 
                x=probability(string)
                if x==1:
                  countofspams+=1
                if x==2:
                  countofequals+=1
                if x==3:
                  countofnonspams+=1

                spam_words1=[" "]
                spam_new_words1=[" "] 
                test_list = [" "]


print('count of spams:  ', countofspams)
print('count of equals:  ', countofequals)
print('count of nonspams:  ', countofnonspams)

single_one_test_path='/content/drive/My Drive/Spam Email Filtering-Anzel Öztürk/test/legitimate/6-1055msg1.txt'
singleone_test = []
string1=" "
with open(single_one_test_path) as file:
  for line in file:
    for word in line.lower().split():
      singleone_test.append(word)

singleone_words=[]
for i in singleone_test:
  if (i.isalnum() and i.isalpha()):
    singleone_words.append(i)

string1=string1.join(singleone_words)

print(string1)
probability(string1)